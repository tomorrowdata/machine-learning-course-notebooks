{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div hidden=True>\n",
    "    author: Marco Angius\n",
    "    company: TomorrowData srl\n",
    "    mail: marco.angius@tomorrowdata.io\n",
    "    notebook-version: nov20\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 3: Supervised Learning\n",
    "This section is meant for learning the Scikit-Learn APIs end provide a playground for machine learning supervised tasks.\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html#) is a library for data mining and data analysis. It  includes models for classification, regression and clustering. It is built on top of NumPy. SciPy and matplotlib. \n",
    "\n",
    "For the purpose of this playground, to get familiar with the Scikit-Learn APis, we would use [Toy Datasets](https://scikit-learn.org/stable/datasets/index.html#toy-datasets) available in the library. \n",
    "\n",
    "Datasets in `sklearn.datasets` return a *Bunch*:\n",
    "> Dictionary-like object, the interesting attributes are: ‘data’, the data to learn, ‘target’, the regression targets, ‘DESCR’, the full description of the dataset, and ‘filename’, the physical location of boston csv dataset (added in version 0.20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mglearn library \n",
    "For visualizing the results obtained with our models we are going to employ an existing library made by Andreas C. Muller (author of the book *Introduction to Machine Learning with Python*). The library is available in the [github repository](https://github.com/amueller/mglearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_diabetes, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from IPython.display import Image\n",
    "from six import StringIO\n",
    "\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_STATE = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset load\n",
    "We will use the **boston house prices** and the **diabetes** dataset for regressions tasks. The **iris** and the **breast cancer** are used for multi-class and binary-class classification tasks respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "boston_houses_ds = load_boston()\n",
    "iris_ds = load_iris()\n",
    "diabetes_ds = load_diabetes()\n",
    "breast_ds = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 1**\n",
    "- check the datasets. Use `print(ds.DESCR)`to print information for each of them.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston_houses_ds.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor: Classification\n",
    "The first model we are going to use is the KNN which is a very simple model to start with. KNN can be used for both for classification or regression tasks. Here we are going to see classification first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 2: Classification with KNN**\n",
    "- split the breast cancer dataset in training and test sets \n",
    "- instantiate a KNN classifier specifying *n_neighbours* in the constructor\n",
    "- fit the model on the training data\n",
    "- make predictions on the test data\n",
    "- observe the obtained performances\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/lightbulb.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; **SciKit-Learn Tip 1: Models**\n",
    "\n",
    "Models in scikit-learn follow all the same API. \n",
    "\n",
    "- to fit a model use the `model.fit(X_test, y_test)`\n",
    "- to make predictions use the `model.predict(X_traing)`\n",
    "\n",
    "In order to split the available data X,y in training and test use the `sklearn.model_selection.train_test_split(X, y)` function.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/lightbulb.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; **SciKit-Learn Tip 2: Metrics**\n",
    "\n",
    "Also it is possible to evaluate the results by means of metrics. There are metrics for [classification](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics) and [regression](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics).\n",
    "\n",
    "For now just use `metrics.accuracy_score(y_true, y_pred)` for classification tasks and `metrics.mean_squared_error(y_true, y_pred)` for regression tasks.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breast_ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = breast_ds.data, breast_ds.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=R_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"distance\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/book.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Theory: Model Complexity** \n",
    "\n",
    "The number of neighbors determines the complexity of the model. \n",
    "\n",
    "A lower value leads to a higher model complexity which means that the model would be very sensitive to noise (when a point of a class is in a region populated the most by the other class points). \n",
    "\n",
    "Vice versa, in the case of an higher number of neighbors used to evaluate the point's class the presence of noise is less relevant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_visual_boundaries(dataset, ranges, model=KNeighborsClassifier):\n",
    "    # use only the first 2 features if more than 2 features\n",
    "    X, y = dataset.data[:, :2] if dataset.data.shape[1] > 2 else dataset.data, dataset.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=R_STATE)\n",
    "    assert len(ranges) <= 3, \"ranges lenght should be less or equal 3\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    for n_neighbors, ax in zip(ranges, axes):\n",
    "        cknn_ = model(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(cknn_, X_test, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "        mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test, ax=ax)\n",
    "        ax.set_title(\"{} neighbor(s)\".format(n_neighbors), fontdict={'fontsize':15})\n",
    "        ax.set_xlabel(dataset.feature_names[0], fontdict={'fontsize':13})\n",
    "        ax.set_ylabel(dataset.feature_names[1], fontdict={'fontsize':13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visual_boundaries(breast_ds, [1, 3, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which k ?\n",
    "It is possible to train different models on different values of k and observe the performance of the model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def k_search_classification(dataset, ranges, random_state=R_STATE):\n",
    "    X, y = dataset.data, dataset.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=random_state)\n",
    "    \n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = ranges\n",
    "    for n in neighbors_settings:\n",
    "        cknn_ = KNeighborsClassifier(n_neighbors=n)\n",
    "        cknn_.fit(X_train, y_train)\n",
    "        training_accuracy.append(cknn_.score(X_train, y_train))\n",
    "        test_accuracy.append(cknn_.score(X_test, y_test))\n",
    "    \n",
    "    plt.figure(figsize=[10, 5])\n",
    "    plt.title(\"Accuracy for different k values\", size=15)\n",
    "    plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "    plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "    plt.ylabel(\"Accuracy\", size=13)\n",
    "    plt.xlabel(\"n_neighbors\", size=13)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor: Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 3: Regression with KNN**\n",
    "- split the diabetes dataset in training and test sets \n",
    "- instantiate a KNN classifier specifying *n_neighbours* in the constructor\n",
    "- fit the model on the training data\n",
    "- make predictions on the test data\n",
    "- observe the obtained performances\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Analysis \n",
    "We can observe how the model works on a single feature of the dataset on the given target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_regression(dataset, ranges, f_number=5):\n",
    "    X, y = dataset.data[::4, f_number], dataset.target[::4]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=R_STATE)\n",
    "    assert len(ranges) <= 3, \"ranges lenght should be less or equal 3\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    line = np.linspace(min(X_train), max(X_train), 1000).reshape(-1, 1)\n",
    "    for n_neighbors, ax in zip(ranges, axes):\n",
    "        rknn_ = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        rknn_.fit(X_train.reshape(-1, 1), y_train)\n",
    "        ax.plot(line, rknn_.predict(line))\n",
    "        ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "        ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "        ax.set_title(\"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\".format(\n",
    "            n_neighbors, \n",
    "            rknn_.score(X_train.reshape(-1,1), y_train),\n",
    "            rknn_.score(X_test.reshape(-1,1), y_test)))\n",
    "        ax.set_xlabel(\"Feature\")\n",
    "        ax.set_ylabel(\"Target\")\n",
    "        axes[0].legend([\"Model predictions\", \"Training data/target\",\"Test data/target\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def k_search_regression(dataset, ranges):\n",
    "    X, y = dataset.data, dataset.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=R_STATE)\n",
    "    \n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = ranges\n",
    "    for n in neighbors_settings:\n",
    "        rknn_ = KNeighborsRegressor(n_neighbors=n)\n",
    "        rknn_.fit(X_train, y_train)\n",
    "        training_accuracy.append(mean_squared_error(y_train, rknn_.predict(X_train)))\n",
    "        test_accuracy.append(mean_squared_error(y_test, rknn_.predict(X_test)))\n",
    "    \n",
    "    plt.figure(figsize=[10, 5])\n",
    "    plt.title(\"MSE for different k values\", size=15)\n",
    "    plt.plot(neighbors_settings, training_accuracy, label=\"training mse\")\n",
    "    plt.plot(neighbors_settings, test_accuracy, label=\"test mse\")\n",
    "    plt.ylabel(\"MSE\", size=13)\n",
    "    plt.xlabel(\"n_neighbors\", size=13)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "The next model we are going to use predict the target by means of a linear function of the input features.\n",
    "The general formula for regression tasks is: \n",
    "\n",
    "$$ \\hat{y} = w[0] * x[0] + w[1] * x[1] + \\dots + w[p] * x[p] + b $$\n",
    "\n",
    "We have also seen that in the case of classification tasks we can employ a linear model for defining decision boundaries: \n",
    "\n",
    "$$ \\hat{y} = w[0] * x[0] + w[1] * x[1] + \\dots + w[p] * x[p] + b > 0 $$\n",
    "\n",
    "For now we focus on regression tasks only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 4: Linear Models**\n",
    "- split the boston houses dataset in training and test sets \n",
    "- fit the model on the training data\n",
    "- make predictions on the test data\n",
    "- observe the obtained performances\n",
    "- check the parameters' magnitude\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston_houses_ds.data, boston_houses_ds.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=R_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, lm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_coefficients_given_models(dataset, models):\n",
    "    models = [models] if not isinstance(models, list) else models\n",
    "    \n",
    "    f = plt.figure(figsize=[12, 7])\n",
    "    ax = f.add_subplot()\n",
    "    for m in models:\n",
    "        ax.plot(range(0, len(dataset.feature_names)), m.coef_, 's', \n",
    "                label=str(m.__class__).strip(\"<>''\").split(\".\")[-1])\n",
    "    \n",
    "    ax.set_title(\"Coefficients magnitued\", fontdict={'fontsize':15})\n",
    "    ax.set_xlabel(\"Coefficient index\", fontdict={'fontsize':13})\n",
    "    ax.set_ylabel(\"Feature\", fontdict={'fontsize':13})\n",
    "    ax.hlines(0, 0, len(m.coef_))\n",
    "    ax.set_xticks(range(0, len(dataset.feature_names)))\n",
    "    ax.set_xticklabels(dataset.feature_names)\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    ax.set_xticklabels(xlabels, rotation=90)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge e Lasso\n",
    "Ordinary Least Square presents a regularization problem due to some of its coefficient magnitudes tends to assume high values fitting on the training data. Ridge and lasso add a constraint on the optimization function in order to limit these phenomena. \n",
    "\n",
    "The Ridge regularization: \n",
    "$$ \\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2 $$\n",
    "\n",
    "The Lasso Regularization: \n",
    "$$ \\min_{w} { \\frac{1}{2n_{\\text{samples}}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 5: Linear Models with regularization**  \n",
    "\n",
    "Try to repeat the regression experiment using `Ridge` and compare the performances with the `LinearRegression` model.\n",
    "\n",
    "To see the different coefficient magnitudes use the `plot_coefficients_given_models` with a given dataset and pass a list of trained models in order to compare the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(boston_houses_ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "The last model we are going to see in this notebook is the Decision Tree for classification. We can compare the different scores obtained with the different classifiers and see witch performs better.\n",
    "\n",
    "Please note that the decision tree has more hyperparameters in comparison with the K-Nearest Neighbor. The ones you can play with are: \n",
    "- `max_depth`: controls the complexity of the model\n",
    "- `min_sample_split`: min number of samples to allow a split in an internal node. If the node is not split it is considered as a leaf, thus the distribution of samples in the leaf would affect the final decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 4: Decision Trees**\n",
    "- split the breast dataset in training and test sets \n",
    "- fit the model on the training data\n",
    "- make predictions on the test data\n",
    "- observe the obtained performances\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Decision Tree Structure\n",
    "It is possible to check how the tree has been built. Use the below `plot_decision_tree(dataset, model)` function to plot the tree. You can also try with different parameters and see how those impact the tree construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/lightbulb.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; **SciKit-Learn Tip 3: Reproducibility**\n",
    "\n",
    "Sometimes we want to have the same output across different runs of the algorithm. Due to the majority of them uses pseudo random generators it is possible to fix the seed of those using the `random_state` parameter.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_decision_tree(dataset, model):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(model, out_file=dot_data,\n",
    "                    feature_names=dataset.feature_names,\n",
    "                    class_names=True,\n",
    "                    filled=True, rounded=True,\n",
    "                    special_characters=True)\n",
    "\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_ds.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree(iris_ds, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 1.1**:  Using the `KNeighborsClassifier` model try to repeat the training using the **iris** dataset.\n",
    "- compute the score using the `accuracy_score`\n",
    "\n",
    "[**SOLUTION**](./solutions/handson3/solution_1.1.py)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 1.2**:  Continure the analysis by manipulating some of the features.\n",
    "- add new features by combining existing ones (see the iris dataset description for some insights).\n",
    "- remove existing features.\n",
    "\n",
    "To help you manipulating the dataset, I have provided you with a function which gives you a `pandas.DataFrame` X_df with the features and a `pandas.Series` with the target.\n",
    "\n",
    "[**SOLUTION**](./solutions/handson3/solution_1.2.py)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def create_dataframe_series(dataset): \n",
    "    return (\n",
    "        pd.DataFrame(dataset.data, columns=[x.replace(\" \", \"_\") for x in dataset.feature_names]), \n",
    "        pd.Series(dataset.target, name=\"target\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 2**:   Using the `KNeighborsRegressor` model try to repeat the training using the **Boston Houses** dataset.\n",
    "- compute the score using the `r2_score` or the `mean_squared_error`\n",
    "\n",
    "[**SOLUTION**](./solutions/handson3/solution_2.py)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 3**:   Using the `DecisionTreeRegressor` model try to repeat the training using the **Boston Houses** dataset.\n",
    "- compute the score using the `r2_score` or the `mean_squared_error`\n",
    "- try different parametrization for the Tree in order to observe the performances. [API](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "[**SOLUTION**](./solutions/handson3/solution_3.py)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 4**: Using the **Breast Cancer**  dataset: \n",
    "\n",
    "- try to repeat the regression experiment using the `Lasso` model and compare the performances with the `LinearRegression` and `Ridge` models.\n",
    "- use `plot_coefficients_given_models` with the Breast Cancer dataset and pass a list of trained models in order to compare the results.\n",
    "[**SOLUTION**](./solutions/handson3/solution_4.py)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div hidden=True>\n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/smashicons\" title=\"Smashicons\">Smashicons</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/lightbulb.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;Icon made by <a href=\"https://www.flaticon.com/authors/pixelmeetup\" title=\"Pixelmeetup\">Pixelmeetup</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/new.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/pixel-perfect\" title=\"Pixel perfect\">Pixel perfect</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/popcorns-arts\" title=\"Icon Pond\">Icon Pond</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/book.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/popcorns-arts\" title=\"Icon Pond\">Icon Pond</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
