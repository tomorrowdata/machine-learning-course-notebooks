{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div hidden=True>\n",
    "    author: Marco Angius\n",
    "    company: TomorrowData srl\n",
    "    mail: marco.anguis@tomorrowdata.io\n",
    "    notebook-version: oct19\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 3: Unsupervised Learning\n",
    "This section is meant for learning the Scikit-Learn APIs end provide a playground for machine learning unsupervised tasks.\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html#) is a library for data mining and data analysis. It  includes models for classification, regression and clustering. It is built on top of NumPy. SciPy and matplotlib. \n",
    "\n",
    "For the purpose of this playground, to get familiar with the Scikit-Learn APis, we would use [Toy Datasets](https://scikit-learn.org/stable/datasets/index.html#toy-datasets) available in the library. \n",
    "\n",
    "Datasets in `sklearn.datasets` return a *Bunch*:\n",
    "> Dictionary-like object, the interesting attributes are: ‘data’, the data to learn, ‘target’, the regression targets, ‘DESCR’, the full description of the dataset, and ‘filename’, the physical location of boston csv dataset (added in version 0.20).\n",
    "\n",
    "In this notebook we also use the `sklearn.datasets.make_blobs` and `sklearn.datasets.make_moons` functions which is of help in generating synthetic data for unsupervised tasks. See the [Generated datasets](https://scikit-learn.org/stable/datasets/index.html#generated-datasets) section for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mglearn library \n",
    "For visualizing the results obtained with our models we are going to employ an existing library made by Andreas C. Muller (author of the book *Introduction to Machine Learning with Python*). The library is available in the [github repository](https://github.com/amueller/mglearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install mglearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer, make_blobs, fetch_lfw_people, make_moons\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "breast_ds = load_breast_cancer()\n",
    "faces_ds = fetch_lfw_people(min_faces_per_person=20, resize=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "Here we are going to see how the effect of data scaling has an impact on supervised models before introducing unsupervised models. \n",
    "\n",
    "The `MinMaxScaler`, `StandardScaler`, `RobustScaler` e `Normalizer` are sklearn models and follows the same API convention that we have seen in the supervised section. This means you can use `fit()` and `transform()` for preparing the model and then scale the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 1: Scaling Data**\n",
    "Using the *breast cancer* dataset apply the different scalers and check how data has changed.\n",
    "- MinMaxScaler: scales features in between the provided ranges \n",
    "- RobustScaler: scales the features bases on the quartiles\n",
    "- StandardScaler: scales the features based on the mean and variance\n",
    "- Normalzer: normalizes the features in order to have unit norm\n",
    "\n",
    "You can use the provided function to plot the data and visually see the differences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X, y = breast_ds.data, breast_ds.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mms = ...\n",
    "X_rs = ...\n",
    "X_ss = ...\n",
    "X_n = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "scaled=[X_mms, X_rs, X_ss, X_n]\n",
    "names = [\"MinMaxScaler\", \"RobustScaler\", \"StandardScaler\", \"Normalizer\"]\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(20, 25) )\n",
    "for i, ax_row in enumerate(axes):\n",
    "    ax_0 = ax_row[0]\n",
    "    ax_1 = ax_row[1]\n",
    "    \n",
    "    ax_0.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    ax_1.scatter(scaled[i][:, 0], scaled[i][:, 1], c=y)\n",
    "    ax_0.set_title(\"Original Data\")\n",
    "    ax_1.set_title(names[i])\n",
    "    for ax in [ax_0, ax_1]:\n",
    "        ax.set_xlabel(\"Feature 1\")\n",
    "        ax.set_ylabel(\"Feature 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 2: Observing model performances for different scalers**\n",
    "\n",
    "Using the scaled data observe the response of a model to the different techniques. \n",
    "\n",
    "The model for this experiment is a Support Vector Machine (SVM) for classification. For details about this model please refer to the [scikit-learn dedicated page](https://scikit-learn.org/stable/modules/svm.html#svm-classification) to SVM.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "In this section we are going to use PCA for both visualization and features extraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 3: PCA - Visualization**\n",
    "\n",
    "We can visualize the *breast cancer* using its first two principal components. \n",
    "\n",
    "- Use `sklearn.decomposition.PCA(n_components)` for selecting the number of principal components and extract the first two components with the trained model. \n",
    "- Use the provided function `plot_projected_data(X_transformed)` to plot the dataset projected onto the new subspace (defined by the principal components).\n",
    "- Observe the two components: they are coefficients and define the two vectors of the new subspace. Use the `plot_heatmap_coefficients(model)` to analyze the coefficients.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_projected_data(X_transformed, dataset=breast_ds):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Projected Data\")\n",
    "    mglearn.discrete_scatter(X_transformed[:, 0], X_transformed[:, 1], dataset.target)\n",
    "    plt.legend(dataset.target_names, loc=\"best\")\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.xlabel(\"First principal component\", size=13)\n",
    "    plt.ylabel(\"Second principal component\", size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_heatmap_coefficients(model, dataset=breast_ds):\n",
    "    plt.matshow(model.components_, cmap='viridis')\n",
    "    plt.yticks([0, 1], [\"First component\", \"Second component\"])\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(dataset.feature_names)),\n",
    "    dataset.feature_names, rotation=60, ha='left')\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Principal components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/book.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Theory: Coefficients interpretability**\n",
    "\n",
    "Observing the coefficient gives an clue about the correlation between the features for the particular direction. In the case of the first component the are all of the same sign meaning that if we observe points increasing in the component direction also the original features tends to increase as well. \n",
    "\n",
    "For the second component is different due to we have mixed signs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 4: PCA - Feature Extraction using Faces dataset**\n",
    "\n",
    "It is possible to use PCA for feature extraction in order to use the new features for training a supervised model and achieve better results in terms of classification scores.\n",
    "\n",
    "- Use *faces* dataset to extract different number of components\n",
    "- Train and test a KNN classifier on the original features\n",
    "- Train and test a KNN classifier on the extracted feature with PCA\n",
    "- Plot, using the provided `plot_pca_face_components()` function, the extracted principal components\n",
    "\n",
    "Data have been prepared in `X_faces` and `y_faces`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "image_shape = faces_ds.images[0].shape\n",
    "def plot_pca_face_components(model):\n",
    "    fix, axes = plt.subplots(3, 5, figsize=(15, 12),\n",
    "    subplot_kw={'xticks': (), 'yticks': ()})\n",
    "    for i, (component, ax) in enumerate(zip(model.components_, axes.ravel())):\n",
    "        ax.imshow(component.reshape(image_shape),cmap='gray')\n",
    "        ax.set_title(\"{}. component\".format((i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X, y = faces_ds.data, faces_ds.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Finally we look into unsupervised learning models and in particular we are going to see **K-Meams** and **DBSCAN**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 5: K-Means**\n",
    "- generate a random dataset with `make_blob()` (by default it has 2 features and 100 samples)\n",
    "- plot the generated random dataset using the `plot_blob(data)` function\n",
    "- apply kmeans to the random dataset using `KMeans(n_clusters=3)`\n",
    "- plot the results with the provided `plot_clusters(data, model)` function \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_clusters(data, model):\n",
    "    # from sklearn \n",
    "    # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Obtain labels for each point in mesh. Use last trained model.\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=[10,7])\n",
    "    plt.clf()\n",
    "    plt.imshow(Z, interpolation='nearest',\n",
    "               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "               cmap=plt.cm.Pastel1, alpha=0.7,\n",
    "               aspect='auto', origin='lower')\n",
    "\n",
    "    plt.plot(data[:, 0], data[:, 1], '.', markersize=10)\n",
    "    # Plot the centroids as a white X\n",
    "    centroids = model.cluster_centers_\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=20, linewidths=3,\n",
    "                color='r', zorder=10)\n",
    "    plt.title('K-means clustering', size=15)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel(\"feature 1\", size=13)\n",
    "    plt.ylabel(\"feature 2\", size=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_blob(data):\n",
    "    f = plt.figure(figsize=[10,7])\n",
    "    ax = f.add_subplot()\n",
    "    ax.scatter(X[:, 0], X[:, 1])\n",
    "    ax.set_title(\"Scatter Plot of random blobs\", fontdict={'fontsize':15})\n",
    "    ax.set_xlabel(\"feature 1\", fontdict={'fontsize':13})\n",
    "    ax.set_ylabel(\"feature 2\", fontdict={'fontsize':13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X, y  = make_blobs(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Task 1**:  Try different values of k and plot the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When K-Means fails\n",
    "K-means has some drawbacks: \n",
    "- it considers only convex shapes (radius of the cluster's centroids)\n",
    "- it assumes cluster of the same size (diameter)\n",
    "- it does not take into account directions' importance \n",
    "- k as hyperparameter\n",
    "\n",
    "Lets consider two cases when kmeans fails to identify potentially \"meaningful\" clusters. The two dataset are already given for this purpose. Then we will see a different model which can solve these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 6: K-Means Failure**\n",
    "- use the `X_blob` to fit and plot the result of kmeans on a stretched blob dataset\n",
    "- use the `X_moons` to fit and plot the result of kmeans on the moons dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_blob, y_blob = make_blobs(random_state=110, n_samples=600)\n",
    "rng = np.random.RandomState(1200)\n",
    "transformation = rng.normal(size=(2, 2))\n",
    "X_blob = np.dot(X_blob, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.05, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DBSCAN\n",
    "We use a more sophisticated clustering algorithm which creates cluster bases on the data point density. One of the advantages of DBSCAN is the needless of setting a k value. For more details about DBSCAN see the scikit-learn [dedicated page](https://scikit-learn.org/stable/modules/clustering.html#dbscan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;  **Exercise 7: DBSCAN**\n",
    "- use DBSCAN to solve the above problems (reuse the already provided data)\n",
    "- try different parameters for DBSCAN: \n",
    "    - `eps`: set this to implicitly control the number of clusters\n",
    "    - `min_sample`: in less dense regions determines if a point a noise one or belonging to a cluster\n",
    "- use the `plot_dbscan_cluster()` to observe the results\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_dbscan_clusters(model, data):\n",
    "    core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\n",
    "    core_samples_mask[model.core_sample_indices_] = True\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "              for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    plt.figure(figsize=[10, 7])\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = data[class_member_mask & core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=14)\n",
    "\n",
    "        xy = data[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6)\n",
    "\n",
    "    plt.title('Estimated number of clusters: %d' % n_clusters_, size=15)\n",
    "    plt.xlabel(\"feature 1\", size=13)\n",
    "    plt.ylabel(\"feature 2\", size=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div hidden=True>\n",
    "<img src=\"./icons/list.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/smashicons\" title=\"Smashicons\">Smashicons</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/lightbulb.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp;Icon made by <a href=\"https://www.flaticon.com/authors/pixelmeetup\" title=\"Pixelmeetup\">Pixelmeetup</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/new.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/pixel-perfect\" title=\"Pixel perfect\">Pixel perfect</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/chemistry.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/popcorns-arts\" title=\"Icon Pond\">Icon Pond</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "\n",
    "<img src=\"./icons/book.png\"  width=\"20\" height=\"20\" align=\"left\"> &nbsp; Icon made by <a href=\"https://www.flaticon.com/authors/popcorns-arts\" title=\"Icon Pond\">Icon Pond</a> from <a href=\"https://www.flaticon.com/\"             title=\"Flaticon\">www.flaticon.com</a>\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
